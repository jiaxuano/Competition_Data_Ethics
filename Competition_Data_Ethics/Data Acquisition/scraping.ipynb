{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open the main website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://www.kaggle.com/competitions?sortOption=reward'\n",
    "# Create a WebDriver instance for Chrome\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "# Visit the website\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gather links for each competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = WebDriverWait(driver, 20).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@id=\"site-content\"]/div[2]/div/div[4]/div/div[2]/div/div[1]/button[1]'))\n",
    ")\n",
    "button.click()\n",
    "\n",
    "competition_links = WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"site-content\"]/div[2]/div/div[5]/div/div/div/ul/li/div/a'))\n",
    ")\n",
    "\n",
    "# Extract href attributes from the top two competitions\n",
    "top_competitions = [link.get_attribute('href') for link in competition_links[:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scraping data from each competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'AI Mathematical Olympiad - Progress Prize 2', 'url': 'https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2', 'overview_text': 'The goal of this competition is to create algorithms and models that can solve tricky math problems written in LaTeX format. Your participation will help to advance AI models’ mathematical reasoning skills and drive frontier knowledge.', 'description_text': \"Note: This is the second AIMO Progress Prize competition. It builds upon the first AIMO Progress Prize competition, which was won in July 2024 by Project Numina. This second competition has an increased prize pool, a new dataset of problems, increased compute for participants and updated rules for using open-source LLMs. The ability to reason mathematically is a critical milestone for AI. Mathematical reasoning is the foundation for solving many complex problems, from engineering marvels to intricate financial models. However, current AI capabilities are limited in this area. The AI Mathematical Olympiad (AIMO) Prize is a $10mn fund to spur the open development of AI models capable of performing as well as top human participants in the International Mathematical Olympiad (IMO). This second AIMO Progress Prize competition has 110 math problems in algebra, combinatorics, geometry and number theory. The difficulty has been increased from the first competition, and the problems are now around the National Olympiad level. The problems have also been designed to be 'AI hard' in terms of the mathematical reasoning required, which was tested against current open LLMs' capabilities. To address the challenge of train-test leakage, the competition uses novel math problems created by an international team of problem solvers. Using this transparent and fair evaluation framework, the competition will help to strengthen the benchmarks for assessing AI models' mathematical reasoning skills, without the risk of contamination from training data.\\nThis latest AIMO Progress Prize competition offers an exciting opportunity to drive innovation in the field of AI for Math, while also fostering healthy competition and supporting open science. Join us as we work towards a future where AI models’ mathematical reasoning skills are accurately and reliably assessed, driving progress and innovation.\", 'dataset_text': 'The competition data comprises 110 mathematics problems similar in style to those of the AIME. The answer to each problem is a non-negative integer between 0 and 999. You should arrive at this number by taking the problem solution modulo 1000. If, for instance, you believe the solution to a problem is 2034, your predicted answer should be 34. You should expect the difficulty of the problems to be roughly at the level of a national Olympiad, although some problems are slightly easier and some are slightly harder. All problems are text-only with mathematical notation in LaTeX. Please see the Overview, Section Note on Language and Notation for details on the notational conventions used. Although some problems may involve geometry, diagrams are not used in any problem. The public test set comprises exactly 50 problems, and the private test set comprises a further distinct set of 50 problems. We also provide a selection of 10 problems for use as reference, called \"reference data\". A pdf with full solutions to the problems from the reference data can be found below. The problems in the private and public sets have been selected to balance both difficulty and subject area. Their difficulty and subject distribution is similar. Please note that this is a Code Competition. You must submit to this competition using the provided Python evaluation API, which serves the test set question by question in random order. To use the API, follow the example in this notebook: AIMO 2 Submission Demo. We give a few placeholder problems in the publicly visible test.csv file to help you author your submissions. These problems are not meant to be representative of the problems in the actual test set. When your submission is scored, this placeholder test data will be replaced with the actual test data. Because of the limited number of problems available, we are taking special precautions to secure the test set against probing. Among other things, during the submission period, the test set will comprise only the 50 public set problems. Once the competition ends, we will rerun all model submissions on the 50 private set problems. You should attempt to make sure your submission will complete successfully on the 50 new private set problems. This may mean ensuring your submission is robust to unexpected inputs, or managing runtime and memory usage.'}\n",
      "{'name': 'Passenger Screening Algorithm Challenge', 'url': 'https://www.kaggle.com/competitions/passenger-screening-algorithm-challenge', 'overview_text': 'Overview text not found', 'description_text': 'While long lines and frantically shuffling luggage into plastic bins isn’t a fun experience, airport security is a critical and necessary requirement for safe travel. No one understands the need for both thorough security screenings and short wait times more than U.S. Transportation Security Administration (TSA). They’re responsible for all U.S. airport security, screening more than two million passengers daily. As part of their Apex Screening at Speed Program, DHS has identified high false alarm rates as creating significant bottlenecks at the airport checkpoints. Whenever TSA’s sensors and algorithms predict a potential threat, TSA staff needs to engage in a secondary, manual screening process that slows everything down. And as the number of travelers increase every year and new threats develop, their prediction algorithms need to continually improve to meet the increased demand. Currently, TSA purchases updated algorithms exclusively from the manufacturers of the scanning equipment used. These algorithms are proprietary, expensive, and often released in long cycles. In this competition, TSA is stepping outside their established procurement process and is challenging the broader data science community to help improve the accuracy of their threat prediction algorithms. Using a dataset of images collected on the latest generation of scanners, participants are challenged to identify the presence of simulated threats under a variety of object types, clothing types, and body types. Even a modest decrease in false alarms will help TSA significantly improve the passenger experience while maintaining high levels of security. This is a two-stage competition. Please read our two-stage FAQs to understand more about what this means. All persons contained in the dataset are volunteers who have agreed to have their images used for this competition. The images may contain sensitive content. We kindly request that you conduct yourself with professionalism, respect, and maturity when working with this data.', 'dataset_text': 'This dataset contains a large number of body scans acquired by a new generation of millimeter wave scanner called the High Definition-Advanced Imaging Technology (HD-AIT) system. The competition task is to predict the probability that a given body zone (out of 17 total body zones) has a threat present. The images in the dataset are designed to capture real scanning conditions. They are comprised of volunteers wearing different clothing types (from light summer clothes to heavy winter clothes), different body mass indices, different genders, different numbers of threats, and different types of threats. Due to restrictions on revealing the types of threats for which the TSA screens, the threats in the competition images are \"inert\" objects with varying material properties. These materials were carefully chosen to simulate real threats. The volunteers used in the first and second stage of the competition will be different (i.e. your algorithm should generalize to unseen people). In addition, you should not make assumptions about the number, distribution, or location of threats in the second stage. All volunteers have agreed to have their images used for this competition. The images may contain sensitive content. We kindly request that you conduct yourself with professionalism, respect, and maturity when working with this data. The data for stage one is more than three terabytes in size. Stage two will have a similar size. Since most internet connections can not reliably download this much data, we are making the full dataset available on multi-regional Google Cloud Storage. Two of the four file formats are downloadable from the competition page directly: All four file formats represent the same underlying scan. They are simply different representations of a 3D image. Kaggle will provide example python code (as a Kernel) that shows how to read the images. (Competition Close Update: This data is no longer available for access at the request of the sponsor) You can read more about accessing Google Cloud Storage buckets here. The large size and proprietary format of this dataset may seem daunting at first. We suggest you start with the smallest version of the images. Over time, the file formats will become familiar. Note that it is possible to work on--and potentially even win--this competition without the raw data files that make up the bulk of the dataset. The data for each scan performed by the HD-AIT system is referred to as an HD-AIT Frame. A frame consists of the following four binary files: Each file is named with a scan Id. These file types are described in more detail below. Due to the dataset size, we have grouped the files into directories based on the file type. This will allow you to start with a small-but-complete set of image files (the .aps files) and work your way up to larger image files, as necessary. The four files generated by the HD-AIT program set have a common file structure. All four files are binary and include a 512 byte header followed by the file\\'s data. The header mostly contains technical scan parameters and is largely identical across all images. With the exception of the field \\'data_scale_factor\\', we do not expect information from the header to be necessary or useful for the competition task. We have preserved the file formats used by the TSA in order to make the result of the competition more readily compatible with the images generated by their scanners. After the binary header, the data is stored sequentially. When referring to the data storage order, the notation indicates, left to right, most significant (largest stride) to least significant (shortest stride) axes. For example, a data order defined as AYX means that the angular axis is the largest stride. Such a file would consist of a series of YX planes incremented in angle. The \\'Projected Image\\' algorithm computes 3D images for 90-degree segments of data that are equally spaced around the region scanned. A maximum value projection of the result of each of these computations is written sequentially into a single file. The result of this is an image file that, when played back plane-by-plane, appears like the object is spinning on the screen. The data type of this file is 16bit unsigned integer. Data scaling is achieved by multiplying each pixel value by the \\'data_scale_factor\\' field in the header. In summary, the \\'Projected Image Angle Sequence\\' file is a series of 2D mmWave snapshots equally spaced in angle around the object. The \\'Combined Image\\' algorithm computes eight 3D images that are equally spaced around the region scanned, and then combines these images into one composite 3D volumetric image. This computation is written into the .a3d file. When played back plane-by-plane, this image displays cross-section slices through the object at sequential heights. The data type of this file is 16bit unsigned integer. Data scaling is achieved by multiplying each pixel value by the \\'data_scale_factor\\' field in the header. In summary, the ‘Combined Image 3D’ file is the full composite 3D image volume stored in sequential height slices order. For visualization purposes, an \\'Angle Sequence File\\' is rendered from the previously described \\'Combined Image 3D\\' data. A projection through the 3D data at sequential angular increments is written contiguously into a single file. Similar to the \\'Projected Image Angle Sequence\\' file, the result of this rendering is an image file that, when played back plane-by-plane, appears like the object is spinning on the screen. The data type of this file is 16bit unsigned integer. Data scaling is achieved by multiplying each pixel value by the \\'data_scale_factor\\' field in the header. In summary, the \\'Combined Image Angle Sequence\\' file is a series of 2D mmWave images equally spaced in angle around the object. The three other types of images (.aps, .a3d, .a3daps) are processed projections based on the raw data file. These projection types were created by engineers with expertise in signal proccessing and are a more readily useful representation of the images. For this reason, and due to its vast size, using the raw data is optional and potentially redudundant with the other data formats. The raw data is captured as follows. A synthetic focusing algorithm performs a waveform calibration operation as the first step. The algorithm combines a set of pre-scan calibrations files to reduce the effect of common mode direct coupling signals and to align the phase component of each waveform captured from each of the array elements. The result of this operation is a calibrated version of the raw data in units of volts. The data is complex floating point words ordered in frequency planes. Every scan in the dataset has a unique (hashed) Id. Every Id will have four associated image files, grouped into folders by their type.'}\n"
     ]
    }
   ],
   "source": [
    "competition_data = []\n",
    "\n",
    "for url in top_competitions:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Ensure the page loads completely\n",
    "    \n",
    "    # Extract competition names\n",
    "    try:\n",
    "        competition_name = WebDriverWait(driver, 2).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, '//*[@id=\"site-content\"]/div[2]/div/div/div[2]/div[2]/div[1]/h1'))\n",
    "        ).text\n",
    "    except:\n",
    "        competition_name = \"Competition name not found\"\n",
    "\n",
    "    # Extract the overview text\n",
    "    try:\n",
    "        overview_text = WebDriverWait(driver, 2).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, '//*[@id=\"abstract\"]/div[1]/div[2]/div/p'))\n",
    "        ).text\n",
    "    except:\n",
    "        overview_text = \"Overview text not found\"\n",
    "\n",
    "    # Extract all paragraphs in the description section\n",
    "    try:\n",
    "        description_paragraphs = WebDriverWait(driver, 2).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"description\"]/div/div[2]/div/div/p'))\n",
    "        )\n",
    "        description_text = ' '.join([para.text for para in description_paragraphs])\n",
    "    except:\n",
    "        description_text = \"Description text not found\"\n",
    "\n",
    "    try:\n",
    "        driver.get(url + '/data')\n",
    "        time.sleep(1)\n",
    "        dataset_paragraphs = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"site-content\"]/div[2]/div/div/div[6]/div[1]/div[1]/div/div[2]/div/div[1]/div/div/div/p'))\n",
    "        )\n",
    "        dataset_description = ' '.join([para.text for para in dataset_paragraphs])\n",
    "    except:\n",
    "        dataset_description = \"Dataset description not found\"\n",
    "\n",
    "\n",
    "    # Store the competition url, overview text, and description text\n",
    "    competition_data.append({\n",
    "        'name' : competition_name,\n",
    "        'url': url,\n",
    "        'overview_text': overview_text,\n",
    "        'description_text': description_text,\n",
    "        'dataset_text' : dataset_description\n",
    "    })\n",
    "\n",
    "# Output the data\n",
    "for data in competition_data:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Eval.Ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open the major website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://eval.ai/web/challenges/list'\n",
    "# Create a WebDriver instance for Chrome\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "# Visit the website\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gather the competition webpage links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eval.ai/web/challenges/challenge-page/2429\n",
      "https://eval.ai/web/challenges/challenge-page/2418\n"
     ]
    }
   ],
   "source": [
    "# Wait for the page to load (this might require adjusting depending on page load time)\n",
    "driver.implicitly_wait(10)  # Adjust the wait time as necessary\n",
    "\n",
    "base_xpath = '//*[@id=\"page-wrap\"]/div/div/div/ui-view/ui-view/section/div[2]/div'\n",
    "\n",
    "# List to hold links\n",
    "competition_links = []\n",
    "\n",
    "# Loop through the first two competition divs\n",
    "for i in range(1, 3):  # Since XPath index starts at 1 and we need first two competitions\n",
    "    competition_xpath = f'{base_xpath}[{i}]/a'\n",
    "    # Find the <a> element and get the href attribute\n",
    "    competition_link = driver.find_element(By.XPATH, competition_xpath).get_attribute('href')\n",
    "    competition_links.append(competition_link)\n",
    "\n",
    "# Print the links\n",
    "for data in competition_links:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scraping from each competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://eval.ai/web/challenges/challenge-page/2429',\n",
       "  'overview': 'Surgical action triplet detection To detect surgical activities as triplets of {`instruments, verb, target`} where :',\n",
       "  'name': 'CholecTriplet Challenge Detection Evaluation'},\n",
       " {'url': 'https://eval.ai/web/challenges/challenge-page/2418',\n",
       "  'overview': \"OpenAD is the first open-world 3D object detection benchmark for autonomous driving. We meticulously selected 2,000 scenes from 5 public datasets and annotated 6,597 3D corner cases for these scenes. Together with the original annotations of these scenes, there are 19,761 objects belonging to 206 different categories. You can utilize OpenAD to evaluate your model's open-world capabilities, encompassing scene generalization, cross-vehicle-type adaptability, open-vocabulary proficiency, and corner case detection aptitude. We provide a toolkit to organize data, load data, and evaluate your model with simple commands. Access the data and code here.\",\n",
       "  'name': 'OpenAD - 3D Object Detection'}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_data_eval = []\n",
    "for url in competition_links:\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # Ensure the page loads completely\n",
    "    try:\n",
    "        paragraphs_xpath = '//*[@id=\"page-wrap\"]/div/div/div/ui-view/ui-view/ui-view/section/div/div[2]/div/div/p'\n",
    "\n",
    "        # Wait until the presence of all paragraph elements is located\n",
    "        description_paragraphs = WebDriverWait(driver, 2).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, paragraphs_xpath))\n",
    "        )\n",
    "\n",
    "        # Extract text from each paragraph\n",
    "        competition_overview = ' '.join([paragraph.text for paragraph in description_paragraphs])\n",
    "    except:\n",
    "        competition_overview = \"Overview text not found\"\n",
    "\n",
    "    try: \n",
    "        name_xpath = '//*[@id=\"page-wrap\"]/div/div/div/ui-view/ui-view/section/div/div[1]/div[2]/div/h4'\n",
    "        competition_name = WebDriverWait(driver, 2).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, name_xpath))\n",
    "        ).text\n",
    "    except:\n",
    "        name = \"Name of competition not found\"\n",
    "    competition_data_eval.append({'url' : url, \n",
    "                                'overview' : competition_overview,\n",
    "                                'name' : competition_name})        \n",
    "\n",
    "competition_data_eval\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drivendata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://www.drivendata.org/competitions/search/?sort=total_prize_purse'\n",
    "# Create a WebDriver instance for Chrome\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "# Visit the website\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.drivendata.org/competitions/group/nist-federated-learning/\n",
      "https://www.drivendata.org/competitions/group/nih-nia-alzheimers-adrd-competition/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Wait for the competition list div to load and locate it using its ID\n",
    "    competition_list_div = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"competition-list\"))\n",
    "    )\n",
    "\n",
    "    # Find all <a> tags within nested layers of the competition list div that have the specific class\n",
    "    competition_links = competition_list_div.find_elements(By.XPATH, \".//a[@class='text-decoration-none'][@href]\")\n",
    "\n",
    "    # Extract href attributes from the first five links only (corrected limit comment)\n",
    "    hrefs = [link.get_attribute('href') for link in competition_links[:2]]  # Limit to first five links\n",
    "\n",
    "    # Output the collected links\n",
    "    for href in hrefs:\n",
    "        print(href)\n",
    "except:\n",
    "    # Clean up: close the browser window\n",
    "    hrefs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Competition: https://www.drivendata.org/competitions/group/nist-federated-learning/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/98/nist-federated-learning-1/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/search/?category=privacy\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/search/?type=privacy\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/105/nist-federated-learning-2-financial-crime-federated/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/144/nist-federated-learning-2-financial-crime-centralized/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/103/nist-federated-learning-2-pandemic-forecasting-federated/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/145/nist-federated-learning-2-pandemic-forecasting-centralized/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/139/nist-federated-learning-3-red-teams/\n",
      "Main Competition: https://www.drivendata.org/competitions/group/nih-nia-alzheimers-adrd-competition/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/301/prepare-challenge-phase-2-report-arena/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/search/?category=None\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/299/competition-nih-alzheimers-acoustic-2/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/300/competition-nih-alzheimers-sdoh-2/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/253/competition-nih-alzheimers-adrd-1/\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/search/?category=health\n",
      "  Sub-Competition: https://www.drivendata.org/competitions/search/?type=health\n"
     ]
    }
   ],
   "source": [
    "main_competition_links = hrefs\n",
    "\n",
    "# Dictionary to hold all sub-competition links for each main competition\n",
    "all_sub_competition_links = {}\n",
    "\n",
    "# Iterate over each main competition link\n",
    "for main_link in main_competition_links:\n",
    "    driver.get(main_link)\n",
    "    try:\n",
    "        # Wait for the sub-competition divs to load\n",
    "        sub_competition_divs = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"competition-subgroup\"))\n",
    "        )\n",
    "        # Collect all hrefs from <a> tags within each subgroup\n",
    "        sub_competition_hrefs = []\n",
    "        for div in sub_competition_divs:\n",
    "            sub_competition_links = div.find_elements(By.XPATH, \".//a[@href]\")\n",
    "            for link in sub_competition_links:\n",
    "                href = link.get_attribute('href')\n",
    "                if href not in sub_competition_hrefs:\n",
    "                    sub_competition_hrefs.append(href)\n",
    "\n",
    "        # Store the collected sub-competition links\n",
    "        all_sub_competition_links[main_link] = sub_competition_hrefs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {main_link}: {str(e)}\")\n",
    "        all_sub_competition_links[main_link] = []\n",
    "\n",
    "# Output the collected links for each competition\n",
    "for main_link, sub_links in all_sub_competition_links.items():\n",
    "    print(f\"Main Competition: {main_link}\")\n",
    "    for link in sub_links:\n",
    "        print(f\"  Sub-Competition: {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
